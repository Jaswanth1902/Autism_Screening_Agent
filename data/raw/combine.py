# merge_autism_datasets.py
import pandas as pd
from scipy.io import arff
import os

# ğŸ”¹ Paths to your datasets
paths = [
    "./Autism-Adolescent-Data.arff",
    "./Autism-Child-Data.arff",
    "./Autism-Adult-Data.arff"
]

dfs = []

for path in paths:
    data, meta = arff.loadarff(path)
    df = pd.DataFrame(data)

    # Decode byte strings (ARFF sometimes stores categorical fields as bytes)
    df = df.applymap(lambda x: x.decode() if isinstance(x, bytes) else x)

    # Add a column to track source dataset
    if "adolescent" in path.lower():
        df["age_group"] = "adolescent"
    elif "child" in path.lower():
        df["age_group"] = "child"
    elif "adult" in path.lower():
        df["age_group"] = "adult"
    else:
        df["age_group"] = "unknown"

    dfs.append(df)
    print(f"âœ… Loaded {path} â†’ shape {df.shape}")

# ğŸ”¹ Combine all datasets
combined_df = pd.concat(dfs, ignore_index=True)
print(f"\nğŸ“Š Combined dataset shape: {combined_df.shape}")

# ğŸ”¹ Optional cleanup
combined_df.columns = combined_df.columns.str.strip()
combined_df.drop_duplicates(inplace=True)

# ğŸ”¹ Save the combined dataset
combined_df.to_csv("../raw/autism_combined_all", index=False)
print("\nğŸ’¾ Saved to: ../raw/autism_combined_all")

# ğŸ”¹ Quick summary
print("\nğŸ“‹ Column summary:")
print(combined_df.info())
print("\nğŸ” Class distribution:")
print(combined_df["Class/ASD"].value_counts())
print("\nğŸ§  Age groups distribution:")
print(combined_df["age_group"].value_counts())
